{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import mmf_setup;mmf_setup.nbinit(hgroot=False)\n",
    "from mmfutils.contexts import NoInterrupt\n",
    "import hfb_dir_init\n",
    "from importlib import reload "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='orange'> Error Analysis</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with the base BCS class which solves the problem in a 1D periodic universe.  This class will form the base for subsequent work, but is limited by the issue discussed above with discrete $k_n$.  As we shall see, there are two forms of errors: UV errors resulting from a limited $k_\\max = \\pi N/L$ and IR errors from the discrete $\\d{k} = \\pi/L$.  To estimate the UV errors, we consider the asymptotic form of the integrals:\n",
    "\n",
    "$$\n",
    "  \\delta_{UV}\\Delta = \\frac{v_0}{2}\\overbrace{2}^{\\pm k}\\int_{k_\\max}^{\\infty}\n",
    "    \\frac{\\d{k}}{2\\pi}\\;\\frac{\\Delta}{\\sqrt{\\epsilon_+^2 + \\Delta^2}} \n",
    "  \\approx v_0\\int_{k_\\max}^{\\infty} \\frac{\\d{k}}{2\\pi}\\;\\frac{2m\\Delta}{\\hbar^2k^2}\n",
    "  = \\frac{v_0m\\Delta}{\\pi\\hbar^2k_\\max} + \\frac{2v_0 m^2\\mu_\\mathrm{eff}}{3\\pi\\hbar^4k_\\max^3},\\\\\n",
    "  \\delta_{UV}n_+ = 2\\int_{k_\\max}^{\\infty}\\frac{\\d{k}}{2\\pi}\n",
    "    \\left[1 - \\frac{\\epsilon_+}{\\sqrt{\\epsilon_+^2 + \\abs{\\Delta}^2}}\\right]\n",
    "  \\approx \\int_{k_\\max}^{\\infty}\\frac{\\d{k}}{2\\pi}\n",
    "    \\frac{4m^2\\abs{\\Delta}^2}{\\hbar^4k^4}\n",
    "  = \\frac{2m^2\\abs{\\Delta}^2}{3\\pi\\hbar^4k_{\\max}^3} \n",
    "    + \\frac{8m^3\\mu_{\\mathrm{eff}}\\abs{\\Delta}^2}{5\\pi \\hbar^6 k_\\max^5}\n",
    "$$\n",
    "\n",
    "The error in $\\Delta$ is largest, so we can set the lattice spacing to achieve the desired accuracy:\n",
    "\n",
    "$$\n",
    "  \\frac{L}{N} \\lesssim \\frac{\\pi^2\\hbar^2}{v_0 m}\\frac{\\delta_{UV}\\Delta}{\\Delta}.\n",
    "$$\n",
    "Estimating the IR errors is more difficult: they arise from the variations of the integrand over the range $\\d{k}$:\n",
    "$$\n",
    "  \\frac{1}{\\d{k}}\\int_{-\\d{k}/2}^{\\d{k}/2}\\d{k_b}\\left\\{\n",
    "    \\frac{\\d{k}}{2\\pi}\\sum_{n}f(k_n + k_b)\n",
    "  \\right\\} \n",
    "  \\approx\n",
    "  \\frac{1}{\\d{k}}\\int_{-\\d{k}/2}^{\\d{k}/2}\\d{k_b}\\left\\{\n",
    "    \\frac{\\d{k}}{2\\pi}\\sum_{n}\\left[f(k_n) + k_bf'(k_n) + \\frac{k_b^2}{2}f''(k_n)\\right]\n",
    "  \\right\\}\\\\\n",
    "  =\n",
    "    \\frac{\\d{k}}{2\\pi}\\sum_{n}\n",
    "    \\left\\{\n",
    "      f(k_n)\n",
    "      +\n",
    "      \\frac{\\d{k}^2}{24}f''(k_n)\n",
    "  \\right\\}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We thus expect the error to scale like \n",
    "\n",
    "$$\n",
    "  \\delta_{IR} \\sim \\frac{\\d{k}^2}{24} = \\frac{\\pi^2}{3L^2}\n",
    "$$\n",
    "\n",
    "but the coefficient is difficult to calculate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pylab inline --no-import-all\n",
    "import bcs;reload(bcs)\n",
    "import homogeneous;reload(homogeneous)\n",
    "\n",
    "delta = 1.0\n",
    "mu_eff = 1.0\n",
    "m = 1.0\n",
    "v_0, n, mu, e_0 = homogeneous.get_BCS_v_n_e(delta=delta, mu_eff=mu_eff)\n",
    "\n",
    "N_twist = 2\n",
    "\n",
    "def get_err(N, L, N_twist=1):\n",
    "    b = bcs.BCS(T=0, N=N, L=L)\n",
    "    R = b.get_R(mus=(mu_eff, mu_eff), delta=delta, N_twist=N_twist)\n",
    "    na = np.diag(R)[:N]/b.dx\n",
    "    nb = (1 - np.diag(R)[N:])/b.dx\n",
    "    kappa = - np.diag(R[:N, N:])/b.dx\n",
    "\n",
    "    k_max = np.pi*N/L\n",
    "    dn_UV = 2*b.m**2*delta**2/3/np.pi/k_max**3 + 8*b.m**3*mu_eff*delta**2/5/np.pi/k_max**5\n",
    "    dd_UV = v_0*b.m*delta/np.pi/k_max + 2*v_0*b.m**2*mu_eff/3/np.pi/k_max**3\n",
    "    return [[na[0].real + nb[0].real, -v_0*kappa[0].real],[dn_UV, dd_UV]]\n",
    "\n",
    "def get_errs(Ns, Ls, N_twist=1):\n",
    "    Ns, Ls = np.asarray(Ns), np.asarray(Ls)\n",
    "    res_NL = []\n",
    "    res_UV = []\n",
    "    for L in Ls:\n",
    "        res_NL_ = []\n",
    "        res_UV_ = []\n",
    "        for N in Ns:\n",
    "            n_d, d_UV = get_err(N=N, L=L, N_twist=N_twist)\n",
    "            res_NL_.append(n_d)\n",
    "            res_UV_.append(d_UV)\n",
    "        res_NL.append(res_NL_)\n",
    "        res_UV.append(res_UV_)\n",
    "    return np.array([res_NL, res_UV])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Ns = 2**np.arange(5, 9)\n",
    "Ls = [1.0, 10.0, 30.0]\n",
    "N_twists = [1, 2, 4]\n",
    "plt.figure(figsize=(5*len(N_twists), 5))\n",
    "for _n, N_twist in enumerate(N_twists):\n",
    "    res_NL, res_UV = get_errs(Ns=Ns, Ls=Ls, N_twist=N_twist)\n",
    "    n_, d_ = np.array(res_NL).T\n",
    "    plt.subplot(101 + len(N_twists)*10 + _n)\n",
    "    for _i, L in enumerate(Ls):\n",
    "        _l, = plt.loglog(Ns, abs(n_[:, _i]-n)/n, '--+', label='$n({})$'.format(L), alpha=0.5)\n",
    "        plt.loglog(Ns, abs(d_[:, _i]-delta)/delta, '--o', c=_l.get_c(),\n",
    "                   label=r'$\\Delta({})$'.format(L), alpha=0.5)\n",
    "        plt.loglog(Ns, abs(res_UV[_i, :, 0])/n, ':', c=_l.get_c())\n",
    "        plt.loglog(Ns, abs(res_UV[_i, :, 1])/delta, ':', c=_l.get_c())\n",
    "    plt.ylabel('Rel err')\n",
    "    plt.xlabel('N')\n",
    "    plt.legend()\n",
    "    plt.title(\"N_twist={}\".format(N_twist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot shows that our estimates of the UV errors is accurate, that the UV errors in $\\Delta$ dominate, and that $L\\approx 25$ is required for reasonable IR convergence.  The following plot shows that the IR errors are quite complicated in structure (shell effects).  Fortunately, we can reduce these errors by explicitly performing the **Bloch (twist) averaging**  (see examples [Lin:2001] ,[Kolorenc:2011]) as we shall describe below.\n",
    "\n",
    "\n",
    "[Lin:2001]: https://arxiv.org/pdf/cond-mat/0101339.pdf 'Twist-averaged Boundary Conditions in Continuum Quantum Monte Carlo'\n",
    "\n",
    "[Kolorenc:2011]: http://www.giovannibachelet.it/MitasRPP2011a.pdf 'Applications of quantum Monte Carlo methods in condensed systems'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want a tolerance of $\\delta \\ln \\Delta < 10^{-4}$, then we must have $L/N < 4.5$.  Computationally, we can conveniently work with $N=2^{10} = 1024$, so $L < 0.46$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "L = 0.46\n",
    "N = 2**8\n",
    "N_twists = 2**np.arange(0,6)\n",
    "\n",
    "res = np.array([get_err(N=N, L=L, N_twist=N_twist)[0]\n",
    "                for N_twist in N_twists])\n",
    "plt.loglog(N_twists, abs(res[:,0] - n)/n, '--+', label='$n$')\n",
    "plt.loglog(N_twists, abs(res[:,1] - delta)/delta, '--o', label=r'$\\Delta$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot shows that we need about $2^5=32$ points in the twist average to accurately determine the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "2**10*np.pi**2/v_0/m*1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Ls = np.linspace(10.0, 30.0, 20)\n",
    "res = []\n",
    "for L in Ls:\n",
    "    b = bcs.BCS(T=0, N=2**10, L=L)\n",
    "    N = b.N\n",
    "    R = b.get_R(mus=(mu_eff, mu_eff), delta=delta)\n",
    "    na = np.diag(R)[:N]/b.dx\n",
    "    nb = (1 - np.diag(R)[N:])/b.dx\n",
    "    kappa = - np.diag(R[:N, N:])/b.dx\n",
    "    #na, nb, kappa\n",
    "    res.append((na[0].real + nb[0].real, -v_0*kappa[0].real))\n",
    "n_, d_ = np.array(res).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_l_n, = plt.loglog(Ls, abs(n_-n)/n, '--+', label='$n$', alpha=0.5)\n",
    "_l_d, = plt.loglog(Ls, abs(d_-delta)/delta, '--o', label=r'$\\Delta$', alpha=0.5)\n",
    "plt.loglog(Ls, abs(1./Ls**3)/n, ':', c=_l_n.get_c())\n",
    "plt.loglog(Ls, abs(1./Ls**3)/delta, ':', c=_l_d.get_c())\n",
    "\n",
    "plt.ylabel('Rel err')\n",
    "plt.xlabel('L')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
