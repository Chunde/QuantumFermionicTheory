{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization with Numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook discussus how to achive high performance of vectorized operations on large chunks of data with [numba](http://numba.pydata.org).\n",
    "<!-- TEASER_END -->$\\newcommand{\\d}{\\mathrm{d}}\\newcommand{\\vect}[1]{\\vec{#1}}\\newcommand{\\abs}[1]{\\lvert#1\\rvert}\\newcommand{\\I}{\\mathrm{i}}\\newcommand{\\braket}[1]{\\langle#1\\rangle}\\newcommand{\\ket}[1]{\\left|#1\\right\\rangle}\\newcommand{\\bra}[1]{\\left\\langle#1\\right|}\\newcommand{\\pdiff}[2]{\\frac{\\partial #1}{\\partial #2}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "{\n",
      "  \"shell_port\": 58649,\n",
      "  \"iopub_port\": 58650,\n",
      "  \"stdin_port\": 58651,\n",
      "  \"control_port\": 58652,\n",
      "  \"hb_port\": 58653,\n",
      "  \"ip\": \"127.0.0.1\",\n",
      "  \"key\": \"791791e2-f1457688316397bcebbca8ca\",\n",
      "  \"transport\": \"tcp\",\n",
      "  \"signature_scheme\": \"hmac-sha256\",\n",
      "  \"kernel_name\": \"\"\n",
      "}\n",
      "\n",
      "Paste the above JSON into a file, and connect with:\n",
      "    $> jupyter <app> --existing <file>\n",
      "or, if you are local, you can connect with just:\n",
      "    $> jupyter <app> --existing kernel-00bc70a4-39b2-4295-84e1-ee24b795352e.json\n",
      "or even just:\n",
      "    $> jupyter <app> --existing\n",
      "if this is the most recent Jupyter kernel you have started.\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import itertools\n",
    "import sympy\n",
    "sympy.init_printing(use_latex=True)\n",
    "%connect_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example we shall start with is motivated by a nuclear physics problem.  We need to compute the following term in a Hamiltonian representing the application of a two-body potential:\n",
    "\n",
    "$$\n",
    "  \\Psi(\\vect{x}_i) = \\sum_{p}V_{p}(\\vect{r}_{p})\\Psi(\\vect{x}_i)\n",
    "$$\n",
    "\n",
    "where $\\vect{x}_i$ are a set of internal (Jacobi) coordinates, and $\\vect{r}_{p}$ are linear combinations of these representing the various relative coordinates in the problem.  Here we define the potential:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Potential(object):\n",
    "    def V(self, p, R):\n",
    "        \"\"\"Dummy potential for the p'th relative coordinate\"\"\"\n",
    "        r2 = np.linalg.norm(R)**2\n",
    "        return np.exp(-r2+(p[0]+1)**p[1])\n",
    "\n",
    "class Basis(object):\n",
    "    def __init__(self, N=3, L=10.0):\n",
    "        x = y = z = np.arange(N, dtype=double)*L/N - L/2.0\n",
    "        self.X = [x[:, None, None, None, None, None],\n",
    "                  y[None, :, None, None, None, None],\n",
    "                  z[None, None, :, None, None, None],\n",
    "                  x[None, None, None, :, None, None],\n",
    "                  y[None, None, None, None, :, None],\n",
    "                  z[None, None, None, None, None, :]]\n",
    "        self.shape = (N,)*6\n",
    "        \n",
    "        # This is the change of basis matrix.  We store\n",
    "        # only the first two relative coordinates, not\n",
    "        # the final center-of-mass variable\n",
    "        self.A =  np.array([[1,     -1,    0   ],\n",
    "                            [0.5,    0.5, -1.  ],\n",
    "                            [1./3,   1./3, 1./3]])\n",
    "        self.Ainv = np.linalg.inv(self.A)\n",
    "\n",
    "    def get_rel_coeffs(self, a, b):\n",
    "        \"\"\"Return the coefficients defining the relative\n",
    "        coordinate from `a` to `b`\n",
    "        \"\"\"\n",
    "        return self.Ainv[a,:] - self.Ainv[b,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis = Basis()\n",
    "pot = Potential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.5,  1. ,  0. ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basis.get_rel_coeffs(1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that the relative coordinate between particle 0 and particle 2 is ``0.5*x[0] + x[1]``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we make a mock wavefunction, and then apply the potential.  This serves as the benchmark (but will be slow):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_V(HPsi, Psi):\n",
    "    for p in [(0,1), (1,2), (0,2)]:\n",
    "        for i0, i1, i2, j0, j1, j2 in itertools.product(*[range(_x.size) for _x in basis.X]):\n",
    "            _ri = [basis.X[0].ravel()[i0], \n",
    "                   basis.X[1].ravel()[i1], \n",
    "                   basis.X[2].ravel()[i2]] # First Jacobi coordinate as a vector\n",
    "            _rj = [basis.X[3].ravel()[j0], \n",
    "                   basis.X[4].ravel()[j1], \n",
    "                   basis.X[5].ravel()[j2]] # Second Jacobi coordinate as a vector\n",
    "            r = np.dot(basis.get_rel_coeffs(*p)[:-1], [_ri, _rj])\n",
    "            HPsi[i0, i1, i2, j0, j1, j2] += pot.V(p, r)*Psi[i0, i1, i2, j0, j1, j2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "Psi = np.random.random(basis.shape) + 0j\n",
    "HPsi = 0*Psi\n",
    "HPsi_ = 0*Psi # Used for timing, which requires a global\n",
    "apply_V(HPsi, Psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(apply_V):\n",
    "    \"\"\"Check that an implementation of apply_V works, and time it.\"\"\"\n",
    "    HPsi0 = 0*Psi\n",
    "    apply_V(HPsi0, Psi)\n",
    "    assert np.allclose(HPsi0, HPsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.4 ms ± 1.41 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "check(apply_V)\n",
    "%timeit apply_V(HPsi_, Psi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To vertorize this loop, one would generally evaluate the potential at all the required points, then perform the multiplication and update.  The problem is that the array would be so large that we will not have space to store it.  Thus, some sort of iterative loop is really required.  Our first step is to consider ``numba``:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by perusing the [Numba Language Specification](http://numba.pydata.org/numba-doc/dev/spec.html).  This will show what things one can do.\n",
    "\n",
    "We start with a simplified loop (assuming all abscisssa to be the same etc.) in order to ensure an easy transition to a compiled version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_V_numba(HPsi, Psi):\n",
    "    \"\"\"These outer parts do not work well in numba\n",
    "    so we do them first, then call the core.\"\"\"\n",
    "    x = basis.X[0].ravel()\n",
    "    for p in [(0,1), (1,2), (0,2)]:\n",
    "        c = basis.get_rel_coeffs(p[0], p[1])[:-1]\n",
    "        #apply_V_core(HPsi=HPsi, Psi=Psi, p=p, c=c, x=x) # kwargs not yet supported\n",
    "        \n",
    "        # Before calling this, we must make sure everything has the correct type!\n",
    "        p, c, x = [np.asarray(_x, dtype=float) for _x in [p, c, x]]\n",
    "        apply_V_core(HPsi, Psi, p, c, x)\n",
    "\n",
    "def apply_V_core(HPsi, Psi, p, c, x):\n",
    "    for i0 in range(x.size):\n",
    "     for i1 in range(x.size):\n",
    "      for i2 in range(x.size):\n",
    "       for j0 in range(x.size):\n",
    "        for j1 in range(x.size):\n",
    "         for j2 in range(x.size):\n",
    "          _ri = x[[i0, i1, i2]] # First Jacobi coordinate as a vector\n",
    "          _rj = x[[j0, j1, j2]] # Second Jacobi coordinate as a vector\n",
    "          r = np.dot(c, [_ri, _rj])\n",
    "          HPsi[i0, i1, i2, j0, j1, j2] += pot.V(p, r)*Psi[i0, i1, i2, j0, j1, j2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.7 ms ± 614 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "check(apply_V_numba)\n",
    "%timeit apply_V_numba(HPsi_, Psi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try applying the [``numba.autojit``](http://numba.pydata.org/numba-doc/dev/dev.html#id7) decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "for n in [#numba.pipeline,\n",
    "          #numba.control_flow.debug,\n",
    "          #numba.closures,\n",
    "          #numba.codegen.debug\n",
    "          ]:\n",
    "    n.logger.setLevel(numba.pipeline.logging.ERROR)\n",
    "\n",
    "x = basis.X[0].ravel()\n",
    "@numba.autojit\n",
    "def apply_V_core(HPsi, Psi, p, c, x):\n",
    "    for i0 in range(x.size):\n",
    "     for i1 in range(x.size):\n",
    "      for i2 in range(x.size):\n",
    "       for j0 in range(x.size):\n",
    "        for j1 in range(x.size):\n",
    "         for j2 in range(x.size):\n",
    "          _ri = x[[i0, i1, i2]] # First Jacobi coordinate as a vector\n",
    "          _rj = x[[j0, j1, j2]] # Second Jacobi coordinate as a vector\n",
    "          r = np.dot(c, [_ri, _rj])\n",
    "          HPsi[i0, i1, i2, j0, j1, j2] += pot.V(p, r)*Psi[i0, i1, i2, j0, j1, j2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.3 ms ± 2.6 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "check(apply_V_numba)\n",
    "%timeit apply_V_numba(HPsi_, Psi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to see what is taking time is to use the annotate feature of numba.  Unfortunately, this does not yet work very well in a notebook, so we shall first write a version of this code in an external file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing apply_V_core_numba.py\n"
     ]
    }
   ],
   "source": [
    "%%file apply_V_core_numba.py\n",
    "import numpy as np\n",
    "import numba\n",
    "\n",
    "def V(p, R):\n",
    "    \"\"\"Dummy potential for the p'th relative coordinate\"\"\"\n",
    "    r2 = np.linalg.norm(R)**2\n",
    "    return np.exp(-r2+(p[0]+1)**p[1])\n",
    "\n",
    "@numba.autojit\n",
    "#@numba.jit('void(c16[:,:,:,:,:,::1], c16[:,:,:,:,:,::1], f8[:], f8[:], f8[:])',\n",
    "#           annotate=True)\n",
    "def apply_V_core(HPsi, Psi, p, c, x):\n",
    "    for i0 in range(x.size):\n",
    "     for i1 in range(x.size):\n",
    "      for i2 in range(x.size):\n",
    "       for j0 in range(x.size):\n",
    "        for j1 in range(x.size):\n",
    "         for j2 in range(x.size):\n",
    "          _ri = x[[i0, i1, i2]] # First Jacobi coordinate as a vector\n",
    "          _rj = x[[j0, j1, j2]] # Second Jacobi coordinate as a vector\n",
    "          r = np.dot(c, [_ri, _rj])\n",
    "          v = V(p, r)\n",
    "          HPsi[i0, i1, i2, j0, j1, j2] += v*Psi[i0, i1, i2, j0, j1, j2]\n",
    "\n",
    "if __name__ == \"\":\n",
    "    # This is executed when called with numba to generate annotations\n",
    "    N = 3\n",
    "    x = np.linspace(-10,10,N)\n",
    "    Psi = np.random.random((N,)*6) + 1j\n",
    "    HPsi = 0*Psi\n",
    "    p = np.zeros(2, dtype=float)\n",
    "    c = np.zeros(2, dtype=float)\n",
    "    apply_V_core(HPsi, Psi, p, c, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import apply_V_core_numba\n",
    "reload(apply_V_core_numba)\n",
    "from apply_V_core_numba import apply_V_core\n",
    "check(apply_V_numba)\n",
    "#%timeit apply_V_numba(HPsi_, Psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m__pycache__\u001b[m\u001b[m                          bcs.pyc                              git-annex.ipynb                      homogeneous.pyc                      mac-os-x.ipynb\n",
      "apply_V_core_numba.py                bdg-equations-in-1d.ipynb            grading-with-google-sheets-wsu.ipynb linux.ipynb                          optimization_with_numba.ipynb\n",
      "bcs.py                               conda-pip-and-all-that.ipynb         homogeneous.py                       logging-with-python.ipynb            path-integrals.ipynb\n",
      "The file /Users/mforbes/work/mmfbb/forbes_group_website/posts/draft/blog/apply_V_core_numba.html does not exist.\n"
     ]
    }
   ],
   "source": [
    "!. /data/apps/anaconda/etc/profile.d/conda.sh; conda activate _tov_test; numba --annotate apply_V_core_numba.py\n",
    "!ls\n",
    "!open apply_V_core_numba.html # On Mac's will open annotated source in another window\n",
    "#from IPython.display import HTML\n",
    "#with open('apply_V_core_numba.html') as _f:\n",
    "#    code = '<iframe> %s </iframe>' % (_f.read() )\n",
    "#HTML(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output looks something like this:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "apply_V_core(HPsi, Psi, p, c, x)\n",
    "apply_V_core_numba.py:33\n",
    "9\t@numba.autojit(annotate=True)\n",
    "10\t#@numba.jit('void(c16[:,:,:,:,:,::1], c16[:,:,:,:,:,::1], f8[:], f8[:], f8[:])',\n",
    "11\t#           annotate=True)\n",
    "12\tdef apply_V_core(HPsi, Psi, p, c, x):\n",
    "13*\t    for i0 in xrange(x.size):\n",
    "14*\t     for i1 in xrange(x.size):\n",
    "15*\t      for i2 in xrange(x.size):\n",
    "16*\t       for j0 in xrange(x.size):\n",
    "17*\t        for j1 in xrange(x.size):\n",
    "18*\t         for j2 in xrange(x.size):\n",
    "19*\t          _ri = x[[i0, i1, i2]] # First Jacobi coordinate as a vector\n",
    "20*\t          _rj = x[[j0, j1, j2]] # Second Jacobi coordinate as a vector\n",
    "21*\t          r = np.dot(c, [_ri, _rj])\n",
    "22*\t          v = V(p, r)\n",
    "23*\t          HPsi[i0, i1, i2, j0, j1, j2] += v*Psi[i0, i1, i2, j0, j1, j2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that almost every line as an \"*\".  This means that the the \"object layer\" is being used which uses the python interpreter and so is slow..  Now we can try to learn how to improve this so that the compiler can generate efficient code.  Here is a list of the problems:\n",
    "\n",
    "* ``x.size`` is not recognized, but one can use ``len(x)``.\n",
    "* Functions like ``np.dot`` and ``no.linalg.norm`` are not supported outside of the object layer.\n",
    "* Slicing for assignment like ``ri[:] = ...`` seems not to be supported outside of the object layer.\n",
    "* Ensure that objects have the correct type... (Apparently numba does not properly cast arguments, even if the type is explicitly specified.)  I was having problems with the argument ``p`` which was being passed as a list of integer for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file apply_V_core_numba.py\n",
    "import numpy as np\n",
    "import numba\n",
    "\n",
    "@numba.autojit(inline=True)\n",
    "#@numba.jit('f8(f8[:])')\n",
    "def norm2(x):\n",
    "    res = abs(x[0])**2\n",
    "    for _i in xrange(1,len(x)):\n",
    "        res += x[_i]**2\n",
    "    return res\n",
    "    \n",
    "@numba.autojit(inline=True)\n",
    "#@numba.jit('f8(f8[:], f8[:])')\n",
    "def V(p, R):\n",
    "    \"\"\"Dummy potential for the p'th relative coordinate\"\"\"\n",
    "    #r2 = np.linalg.norm(R)**2\n",
    "    r2 = norm2(R)\n",
    "    #r2 = R[0]**2 + R[1]**2 + R[2]**2\n",
    "    return np.exp(-r2+(p[0]+1)**p[1])\n",
    "\n",
    "@numba.autojit\n",
    "#@numba.jit('void(c16[:,:,:,:,:,::1], c16[:,:,:,:,:,::1], f8[:], f8[:], f8[:])',\n",
    "#           annotate=True)\n",
    "def apply_V_core(HPsi, Psi, p, c, x):\n",
    "    ri = np.zeros(3, dtype=float)\n",
    "    rj = np.zeros(3, dtype=float)\n",
    "    for i0 in xrange(len(x)):\n",
    "     for i1 in xrange(len(x)):\n",
    "      for i2 in xrange(len(x)):\n",
    "       for j0 in xrange(len(x)):\n",
    "        for j1 in xrange(len(x)):\n",
    "         for j2 in xrange(len(x)):\n",
    "          ri[0], ri[1], ri[2] = x[i0], x[i1], x[i2] # This works, but is ugly...\n",
    "          rj[0], rj[1], rj[2] = x[j0], x[j1], x[j2] # This works, but is ugly...\n",
    "          #ri[:] = x[i0], x[i1], x[i2]               # This does not compile\n",
    "          #rj[:] = x[[j0, j1, j2]]                   # Neither does this\n",
    "          r = c[0] * ri + c[1] * rj  # This works, but crashes annotate...\n",
    "          v = V(p, r)\n",
    "          HPsi[i0, i1, i2, j0, j1, j2] += v*Psi[i0, i1, i2, j0, j1, j2]\n",
    "\n",
    "if __name__ in [\"__main__\", \"\"]:\n",
    "    # This is executed when called with numba to generate annotations\n",
    "    N = 3\n",
    "    x = np.linspace(-10,10,N)\n",
    "    Psi = np.random.random((N,)*6) + 1j\n",
    "    HPsi = 0*Psi\n",
    "    p = np.zeros(2, dtype=float)\n",
    "    c = np.zeros(2, dtype=float)\n",
    "    apply_V_core(HPsi, Psi, p, c, x)\n",
    "    \n",
    "    import time\n",
    "    N = 10\n",
    "    tic = time.time()\n",
    "    for n in xrange(N):\n",
    "        apply_V_core(HPsi, Psi, p, c, x)\n",
    "    print(\"%gms\" % ((time.time() - tic)/N*1000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apply_V_core_numba\n",
    "reload(apply_V_core_numba)\n",
    "from apply_V_core_numba import apply_V_core\n",
    "check(apply_V_numba)\n",
    "%timeit apply_V_numba(HPsi_, Psi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see that everything happens in under a microsecond.  Unfortunately annotate no-longer works because of the line ``r = c[0] * ri + c[1] * rj``...  Not sure why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static Compilation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One problem with using JIT compilation is that it can take a while to get going since the compiler needs to be called.  To alliviate this, it would be great if the compilation results could be cached between runs, but this feature is not yet available in numba.  (See [Issue #224](https://github.com/numba/numba/issues/224).)  Instead, we must resort to [static compilation](http://numba.pydata.org/numba-doc/dev/pycc.html).  Here we test this with both functions and classes (the latter can be useful to maintain state.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file static_compilation.py\n",
    "from numba import *\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def norm2(x):\n",
    "    res = x[0]**2\n",
    "    for _i in xrange(len(x)):\n",
    "        res += x[_i]**2\n",
    "    return res\n",
    "\n",
    "export('norm2 f8(f8[:])')(norm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pycc --python static_compilation.py -o sc.so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file static_compilation2.py\n",
    "from numba import *\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "@autojit\n",
    "def norm2(x):\n",
    "    res = x[0]**2\n",
    "    for _i in xrange(len(x)):\n",
    "        res += x[_i]**2\n",
    "    return res\n",
    "\n",
    "@autojit\n",
    "class C(object):\n",
    "    def __init__(self, offset=1.0):\n",
    "        self.offset = offset\n",
    "\n",
    "    @void(c16[:,:,:,:,:,:],c16[:,:,:,:,:,:], f8[:])\n",
    "    def apply_V(self, VPsi, Psi, x):\n",
    "        for i0 in xrange(len(x)):\n",
    "            for i1 in xrange(len(x)):\n",
    "                for i2 in xrange(len(x)):\n",
    "                    for i3 in xrange(len(x)):\n",
    "                        for i4 in xrange(len(x)):\n",
    "                            for i5 in xrange(len(x)):\n",
    "                                VPsi[i0,i1,i2,i3,i4,i5] = (norm2(x) + self.offset)*Psi[i0,i1,i2,i3,i4,i5]\n",
    "\n",
    "export('norm2 f8(f8[:])')(norm2)\n",
    "\n",
    "if __name__ in [\"__main__\", \"\"]:\n",
    "    # This is executed when called with numba to generate annotations\n",
    "    N = 3\n",
    "    x = np.linspace(-10,10,N)\n",
    "    Psi = np.random.random((N,)*6) + 1j\n",
    "    HPsi = 0*Psi\n",
    "    c = C(0.1)\n",
    "    c.apply_V(HPsi, Psi, x)\n",
    "    \n",
    "    import time\n",
    "    N = 10\n",
    "    tic = time.time()\n",
    "    for n in xrange(N):\n",
    "        c.apply_V(HPsi, Psi, x)\n",
    "    print(\"%gms\" % ((time.time() - tic)/N*1000,))          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pycc static_compilation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "@numba.autojit # This compiles when the function is called the first time.\n",
    "#@jit(numba.f8(numba.f8))  # This compiles when the definition is loaded\n",
    "def sq(x):\n",
    "    for i in xrange(100000):\n",
    "        x += x*x\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "tic = time.time()\n",
    "sq(6.0);print time.time() - tic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMP: ``prange``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we demonstrate how to use multiple cores on a single node using ``numba.prange``.  A couple of points to note:\n",
    "\n",
    "* ``prange`` cannot be nested, so you must unravel the loops you want to parallelize.\n",
    "* One cannot use ``if`` statements in a ``prange`` loop, but they can be hidden inside a function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numba\n",
    "for n in [numba.pipeline,\n",
    "          numba.control_flow.debug,\n",
    "          numba.closures,\n",
    "          numba.codegen.debug]:\n",
    "    n.logger.setLevel(numba.pipeline.logging.ERROR)\n",
    "\n",
    "for n in [numba.pipeline,\n",
    "          numba.control_flow.debug,\n",
    "          numba.closures,\n",
    "          numba.codegen.debug]:\n",
    "    n.logger.setLevel(numba.pipeline.logging.ERROR)\n",
    "\n",
    "\n",
    "@numba.jit(numba.f8(numba.f8[:]), inline=True)\n",
    "def norm2(x):\n",
    "    res = abs(x[0])**2\n",
    "    for i in xrange(1,len(x)):\n",
    "        res += abs(x[i])**2\n",
    "    return res\n",
    "\n",
    "@numba.jit(numba.f8(numba.int_, numba.f8), inline=True)\n",
    "def g(i2, x):\n",
    "    if i2 % 2 == 0:\n",
    "        return np.sin(x)\n",
    "    else:\n",
    "        return np.cos(x)\n",
    "def g_np(i2, x):\n",
    "    return np.where(i2 % 2 == 0, np.sin(x), np.cos(x))\n",
    "\n",
    "@numba.jit(numba.void(numba.f8[:,:,:],numba.f8[:,:,:]))\n",
    "def f(X, Y):\n",
    "    Nx, Ny, Nz = X.shape\n",
    "    for i0 in xrange(Nx):\n",
    "        for i1 in xrange(Ny):\n",
    "            for i2 in xrange(Nz):\n",
    "                Y[i0, i1, i2] = g(i2, X[i0, i1, i2])\n",
    "\n",
    "@numba.jit(numba.void(numba.f8[:,:,:],numba.f8[:,:,:]))\n",
    "def fp(X, Y):\n",
    "    Nx, Ny, Nz = X.shape\n",
    "    _r = np.zeros(Nx, dtype=float)\n",
    "    for i0 in numba.prange(Nx):\n",
    "        for i1 in xrange(Ny):\n",
    "            for i2 in xrange(Nz):\n",
    "                Y[i0, i1, i2] = norm2(_r) * g(i2, X[i0, i1, i2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "shape = (8*2, 20**2,20**2)\n",
    "i2 = np.arange(shape[-1])[None,None,:]\n",
    "X = np.random.random(shape)\n",
    "Y = 0*X\n",
    "f(X,Y)\n",
    "assert np.allclose(Y, g_np(i2,X))\n",
    "%timeit Y[::] = np.sin(X)\n",
    "%timeit f(X,Y)\n",
    "%timeit fp(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numba\n",
    "\n",
    "@numba.jit(numba.f8(numba.f8[:]), inline=True)\n",
    "def norm2(x):\n",
    "    res = abs(x[0])**2\n",
    "    for i in xrange(1,len(x)):\n",
    "        res += abs(x[i])**2\n",
    "    return res\n",
    "\n",
    "@numba.jit(numba.f8(numba.int_, numba.f8), inline=True)\n",
    "def g(i2, x):\n",
    "    if i2 % 2 == 0:\n",
    "        return np.sin(x)\n",
    "    else:\n",
    "        return np.cos(x)\n",
    "def g_np(i2, x):\n",
    "    return np.where(i2 % 2 == 0, np.sin(x), np.cos(x))\n",
    "\n",
    "@numba.jit(numba.void(numba.f8[:,:,:],numba.f8[:,:,:]))\n",
    "def f(X, Y):\n",
    "    Nx, Ny, Nz = X.shape\n",
    "    _r = np.zeros(Nx, dtype=float)\n",
    "    for i0 in xrange(Nx):\n",
    "        for i1 in xrange(Ny):\n",
    "            for i2 in xrange(Nz):\n",
    "                Y[i0, i1, i2] = norm2(_r) * g(i2, X[i0, i1, i2])\n",
    "\n",
    "@numba.jit(numba.void(numba.f8[:,:,:],numba.f8[:,:,:]))\n",
    "def fp(X, Y):\n",
    "    Nx, Ny, Nz = X.shape\n",
    "    _r = np.zeros(Nx, dtype=float)\n",
    "    for i0 in numba.prange(Nx):\n",
    "        for i1 in xrange(Ny):\n",
    "            for i2 in xrange(Nz):\n",
    "                Y[i0, i1, i2] = norm2(_r) * g(i2, X[i0, i1, i2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numexpr\n",
    "def f(x):\n",
    "    return math.sin(x)\n",
    "A = np.random.random((10,10))\n",
    "B = 0*A\n",
    "numexpr.evaluate('f(A)', dict(f=f, A=A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we compare several techniques for vectorization.  We shall apply the ``sin`` operator to a complex array and sum the result in the end to ensure the calculation proceeded correctly.  Note that the choise of ``sin`` may not be optimal as the time it takes depends on the argument, but if we use the same initial array, we should get a reasonable comparison.  As a benchmark, we start with a straightforward C++ version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Thread C++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sin.cpp\n"
     ]
    }
   ],
   "source": [
    "%%file sin.cpp\n",
    "#include <iostream>\n",
    "#include <complex>\n",
    "#include <ctime>\n",
    "\n",
    "typedef std::complex<double> complex;\n",
    "\n",
    "int main(int argc, char ** argv) {\n",
    "  const int N=16;\n",
    "  complex *X = new complex[N*N*N*N*N*N];\n",
    "  complex *Y = new complex[N*N*N*N*N*N];\n",
    "  int i,j;\n",
    "  for (i=0;i<N*N*N*N*N*N;++i) \n",
    "    X[i] = complex(static_cast<double>(i),1.0);\n",
    "\n",
    "  time_t start = time(0);\n",
    "  for (j=0;j<10;++j) {\n",
    "#pragma omp parallel for private(i)\n",
    "    for (i=0;i<N*N*N*N*N*N;++i) {\n",
    "      Y[i] = std::sin(X[i]);\n",
    "    }\n",
    "  }\n",
    "  time_t end = time(0);\n",
    "  double time = difftime(end, start);  \n",
    "  std::cout << \"Loop took \" << time << \"s\\n\";\n",
    "\n",
    "  complex res = 0.0;\n",
    "  for (i=0;i<N*N*N*N*N*N;++i) {\n",
    "    res += Y[i];\n",
    "  }\n",
    "  std::cout << \"res = \" << res << \"\\n\";\n",
    "  \n",
    "  delete X;\n",
    "  delete Y;\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1msin.cpp:17:9: \u001b[0m\u001b[0;1;35mwarning: \u001b[0m\u001b[1munknown pragma ignored [-Wunknown-pragmas]\u001b[0m\n",
      "#pragma omp parallel for private(i)\n",
      "\u001b[0;1;32m        ^\n",
      "\u001b[0m1 warning generated.\n",
      "Loop took 11s\n",
      "res = (1.12921,-0.618922)\n",
      "\n",
      "real\t0m10.872s\n",
      "user\t0m10.697s\n",
      "sys\t0m0.173s\n"
     ]
    }
   ],
   "source": [
    "!rm -f sin\n",
    "!clang++ -Wall -O4 sin.cpp -o sin  # clang++ is the Apple compiler based on LLVM\n",
    "!time ./sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop took 2s\n",
      "res = (1.12921,-0.618922)\n",
      "\n",
      "real\t0m2.785s\n",
      "user\t0m19.097s\n",
      "sys\t0m0.183s\n"
     ]
    }
   ],
   "source": [
    "!rm -f sin_omp\n",
    "!g++ -fopenmp -lgomp -Wall -O4 sin.cpp -o sin_omp  # clang++ is the Apple compiler based on LLVM\n",
    "!time ./sin_omp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the canonically way of performing such calculations in python.  It would be extremely inefficient to use a ``for`` loop as python does not handle them well.  If you can structure your calculation to use ``numpy`` in this matter – applying a single function to an array – then things will be much faster as the loop over elements of the array is performed inside the compiled functions.  Unfortunately, to realize this speedup, the function must be compiled with the looping inside, so you cannot easily use this functionality for custom functions.  (There is a ``numpy.vectorize`` function that appears to do this, but it is only for convenience, not for performance.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.1292070152657678-0.61892247940959455j)\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "N = 16\n",
    "shape = (N,)*6\n",
    "X = (np.arange(N**6) + 1.0j).reshape(shape)\n",
    "Y = 0*X\n",
    "sinX = np.sin(X) \n",
    "res = sinX.sum()\n",
    "print repr(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.8 s, sys: 914 ms, total: 14.7 s\n",
      "Wall time: 14.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in xrange(10):\n",
    "    Y = np.sin(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumExpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numexpr evaluates compiled expressions on a virtual machine, and pays careful attention to memory bandwith.  The first time a function is called, it will be compiled – subsequent calls will be fast.  One can also use an explicit instantiation of a function via the ``NumExpr`` class (but this is not very well documented – check the ``numexpr`` sources.)  One strategy that I often use is to generate the expression symbolically using ``sympy``.  One can then perform some symbolic optimizations (or compute derivatives and other symbolic manipulations) and compile the final expressions into an efficient function.  This approach is also one of the easiest ways of to leverage multiple cores (the threading is done using the ``ctypes`` interface that allows ``numexpr`` to release the GIL.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numexpr\n",
      "(1.12920701527-0.61892247941j)\n"
     ]
    }
   ],
   "source": [
    "import numexpr\n",
    "numexpr.set_num_threads(8)\n",
    "apply_sin_numexpr = numexpr.NumExpr('sin(X)', signature=[('X', complex)], optimization='aggressive')\n",
    "print(\"numexpr\")\n",
    "Y = apply_sin_numexpr(X)\n",
    "assert np.allclose(Y, sinX)\n",
    "print Y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 3.74 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for i in xrange(10):\n",
    "    Y = apply_sin_numexpr(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ``scipy.weave.inline``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``scipy.weave.inline`` function can be used to compile code on the fly.  The advantage here is that one can allocate and prepare the arrays in python, then just drop into c++ for the core loop.  Another less obvious benefit is tha one can use python as a meta-language to dynamically generate the C++ code. (One use is to generate multiply nested loops to run over N-dimensions where N changes at runtime.)\n",
    "\n",
    "The generated boiler plate provides both 1D and multi-dimensional access to the array elements, size, etc. through various macros.  Unfortunately, there is no easy way that I know of to utilize multiple cores with this approach (though, of course, one could use the full power of C++, but this is not simple).\n",
    "\n",
    "**NOTE: Weave only works with Python 2***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-e17d59fa9d50>, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-e17d59fa9d50>\"\u001b[0;36m, line \u001b[0;32m22\u001b[0m\n\u001b[0;31m    print Y.sum()\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from weave import inline\n",
    "\n",
    "src = \"\"\"\n",
    "const int N=16;\n",
    "int i,j;\n",
    "for (j=0;j<10;++j){\n",
    "  for (i=0;i<N*N*N*N*N*N;++i) {\n",
    "    Y[i] = std::sin(X[i]);\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "_args = dict(code=src,\n",
    "             arg_names=['X', 'Y'],\n",
    "             extra_compile_args=[\"-O3\",],\n",
    "             local_dict=dict(N=N, X=X, Y=Y))\n",
    "def apply_sin_inline(X, Y):\n",
    "    inline(code=src, arg_names=['X', 'Y'])\n",
    "Y = 0*X\n",
    "%time apply_sin_inline(X,Y)\n",
    "assert np.allclose(Y, sinX)\n",
    "print Y.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``numba`` package provides a way to convert a subset of python code into LLVM which then gets compiled.  There are two options – the simplest is to use the ``autojit`` decorator, which will determine the required types from the arguments when the function is called.  The second approach is to use the ``jit`` decorator, which allows one to specify the type (and which will perform the compilations on import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import numba\n",
    "for n in [numba.pipeline,           # Ignore some debug info\n",
    "          numba.control_flow.debug,\n",
    "          numba.closures,\n",
    "          numba.codegen.debug]:\n",
    "    n.logger.setLevel(numba.pipeline.logging.ERROR)\n",
    "\n",
    "@numba.autojit\n",
    "def apply_sin_numba(X, Y):\n",
    "    x0, x1, x2, y0, y1, y2 = X.shape\n",
    "    for i0 in xrange(x0):\n",
    "        for i1 in xrange(x1):\n",
    "            for i2 in xrange(x2):\n",
    "                for j0 in xrange(y0):\n",
    "                    for j1 in xrange(y1):\n",
    "                        for j2 in xrange(y2):\n",
    "                            Y[i0,i1,i2,j0,j1,j2] = np.sin(X[i0,i1,i2,j0,j1,j2])\n",
    "\n",
    "# Note that the following also work as \"array expressions\" but take a lot longer to compile...\n",
    "@numba.autojit\n",
    "def _apply_sin_numba(X, Y):\n",
    "    for i in xrange(len(X)):\n",
    "        Y[i] = np.sin(X[i])\n",
    "\n",
    "@numba.autojit\n",
    "def _apply_sin_numba(X, Y):\n",
    "    Y[...] = np.sin(X[...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.45 s, sys: 16.7 ms, total: 1.47 s\n",
      "Wall time: 1.49 s\n"
     ]
    }
   ],
   "source": [
    "Y = 0*X\n",
    "%time apply_sin_numba(X, Y)  # This will include the compiliation time.\n",
    "assert np.allclose(Y, sinX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.5 s, sys: 4.3 ms, total: 12.5 s\n",
      "Wall time: 12.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for n in range(10):\n",
    "    apply_sin_numba(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use explicit types with ``jit``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 223 ms, sys: 4.83 ms, total: 228 ms\n",
      "Wall time: 234 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_type = numba.c16[:,:,:,:,:,::1]\n",
    "_jit = numba.jit(numba.void(X_type, X_type))\n",
    "\n",
    "@_jit\n",
    "def apply_sin_numba_jit(X, Y):\n",
    "    x0, x1, x2, y0, y1, y2 = X.shape\n",
    "    for i0 in xrange(x0):\n",
    "        for i1 in xrange(x1):\n",
    "            for i2 in xrange(x2):\n",
    "                for j0 in xrange(y0):\n",
    "                    for j1 in xrange(y1):\n",
    "                        for j2 in xrange(y2):\n",
    "                            Y[i0,i1,i2,j0,j1,j2] = np.sin(X[i0,i1,i2,j0,j1,j2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.26 s, sys: 247 µs, total: 1.26 s\n",
      "Wall time: 1.26 s\n"
     ]
    }
   ],
   "source": [
    "Y = 0*X\n",
    "%time apply_sin_numba_jit(X, Y)  # This will include the compiliation time.\n",
    "assert np.allclose(Y, sinX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.5 s, sys: 4.18 ms, total: 12.5 s\n",
      "Wall time: 12.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for n in range(10):\n",
    "    apply_sin_numba_jit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numba allows one to use multiple threads by using ``numba.prange``, but this places even more restrictions on what can appear in the loop.  For example, one cannot use conditional (but they can be used in nested function calls).  This take a LOT longer to compile though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "000010:INFO:numba.llvm_types:\n",
      "\u001b[1mINFO -- llvm_types:107:build_int_cast\u001b[0m\n",
      "Warning: Perfoming downcast.  May lose information.\n",
      "000011:INFO:numba.llvm_types:\n",
      "\u001b[1mINFO -- llvm_types:107:build_int_cast\u001b[0m\n",
      "Warning: Perfoming downcast.  May lose information.\n",
      "000012:INFO:numba.llvm_types:\n",
      "\u001b[1mINFO -- llvm_types:107:build_int_cast\u001b[0m\n",
      "Warning: Perfoming downcast.  May lose information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------- Numba Encountered Errors or Warnings ---------------------\n",
      "            for i2 in xrange(x2):            \n",
      "^\n",
      "Warning 5:0: local variable 'i1' might be referenced before assignment\n",
      "\n",
      "            for i2 in xrange(x2):            \n",
      "^\n",
      "Warning 5:0: local variable 'i2' might be referenced before assignment\n",
      "\n",
      "            for i2 in xrange(x2):            \n",
      "^\n",
      "Warning 5:0: local variable 'j0' might be referenced before assignment\n",
      "\n",
      "            for i2 in xrange(x2):            \n",
      "^\n",
      "Warning 5:0: local variable 'j1' might be referenced before assignment\n",
      "\n",
      "            for i2 in xrange(x2):            \n",
      "^\n",
      "Warning 5:0: local variable 'j2' might be referenced before assignment\n",
      "--------------------------------------------------------------------------------\n",
      "CPU times: user 1min 6s, sys: 508 ms, total: 1min 6s\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "@_jit\n",
    "def apply_sin_numba_p(X, Y):\n",
    "    \"\"\"Multi-threaded version of numba sin\"\"\"\n",
    "    x0, x1, x2, y0, y1, y2 = X.shape\n",
    "    for i0 in numba.prange(x0):\n",
    "        for i1 in xrange(x1):\n",
    "            for i2 in xrange(x2):\n",
    "                for j0 in xrange(y0):\n",
    "                    for j1 in xrange(y1):\n",
    "                        for j2 in xrange(y2):\n",
    "                            Y[i0,i1,i2,j0,j1,j2] = np.sin(X[i0,i1,i2,j0,j1,j2])\n",
    "#@_jit\n",
    "def _apply_sin_numba_p(X, Y):\n",
    "    for i in numba.prange(len(X)):\n",
    "        Y[i] = np.sin(X[i])\n",
    "\n",
    "#@_jit\n",
    "def apply_sin_pr(X, Y):\n",
    "    \"\"\"Multi-threaded version of numba sin with reversed indexing\"\"\"\n",
    "    x0, x1, x2, y0, y1, y2 = X.shape\n",
    "    for j2 in numba.prange(y2):\n",
    "        for j1 in xrange(y1):\n",
    "            for j0 in xrange(y0):\n",
    "                for i2 in xrange(x2):\n",
    "                    for i1 in xrange(x1):\n",
    "                        for i0 in xrange(x0):\n",
    "                            Y[i0,i1,i2,j0,j1,j2] = np.sin(X[i0,i1,i2,j0,j1,j2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.52 s, sys: 2.61 ms, total: 2.52 s\n",
      "Wall time: 343 ms\n"
     ]
    }
   ],
   "source": [
    "Y = 0*X\n",
    "%time apply_sin_numba_p(X, Y)  # This will include the compiliation time.\n",
    "assert np.allclose(Y, sinX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.7 s, sys: 30.3 ms, total: 27.7 s\n",
      "Wall time: 3.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for n in range(10):\n",
    "    apply_sin_numba_p(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy\n",
      "1 loops, best of 3: 1.42 s per loop\n",
      "numba\n",
      "1 loops, best of 3: 1.28 s per loop\n",
      "weave.inline\n",
      "1 loops, best of 3: 10.6 s per loop\n",
      "numba threaded\n",
      "1 loops, best of 3: 363 ms per loop\n",
      "numexpr\n",
      "1 loops, best of 3: 362 ms per loop\n"
     ]
    }
   ],
   "source": [
    "print(\"numpy\")\n",
    "%timeit Y = np.sin(X)\n",
    "Y = np.sin(X); assert np.allclose(Y, sinX)\n",
    "\n",
    "print(\"numba\")\n",
    "%timeit apply_sin_numba(X,Y)\n",
    "Y = 0*X; apply_sin_numba(X,Y); assert np.allclose(Y, sinX)\n",
    "\n",
    "print(\"weave.inline\")\n",
    "%timeit apply_sin_inline(X, Y)\n",
    "Y = 0*X; apply_sin_inline(X, Y); assert np.allclose(Y, sinX)\n",
    "\n",
    "print(\"numba threaded\")\n",
    "%timeit apply_sin_numba_p(X, Y)\n",
    "Y = 0*X; apply_sin_numba_p(X,Y); assert np.allclose(Y, sinX)\n",
    "\n",
    "print(\"numexpr\")\n",
    "%timeit Y = apply_sin_numexpr(X)\n",
    "Y = apply_sin_numexpr(X); assert np.allclose(Y, sinX)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:_tov_test]",
   "language": "python",
   "name": "conda-env-_tov_test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "nikola": {
   "category": "",
   "date": "2013-11-26 12:45:25 PST",
   "description": "",
   "link": "",
   "slug": "optimization_with_numba",
   "tags": "",
   "title": "Optimization with Numba",
   "type": "text"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
